{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f04bfe0",
   "metadata": {},
   "source": [
    "# ğŸ“¡ ESP32 Access Point Implementation for Bengali Sign Language Recognition\n",
    "\n",
    "This notebook implements fetching sensor data from ESP32 using Access Point mode instead of WebSocket, and uses the trained LSTM model for real-time Bengali character recognition.\n",
    "\n",
    "## ğŸ¯ Features:\n",
    "- ğŸ“¡ ESP32 Access Point HTTP communication\n",
    "- ğŸ¤– LSTM Bengali Sign Language recognition  \n",
    "- ğŸ”„ Real-time continuous prediction\n",
    "- ğŸ“Š Live monitoring and statistics\n",
    "- ğŸ›¡ï¸ Connection resilience and error handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "302b070a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All required libraries imported successfully!\n",
      "ğŸš€ INITIALIZING BENGALI SIGN LANGUAGE RECOGNITION SYSTEM...\n",
      "============================================================\n",
      "ğŸ”„ Loading Bengali Sign Language LSTM Model...\n",
      "ğŸ“‚ Loading LSTM model...\n",
      "âœ… LSTM model loaded: (None, 1, 10)\n",
      "ğŸ“‚ Loading preprocessing components...\n",
      "âœ… Scaler loaded: StandardScaler\n",
      "âœ… Label encoder loaded with 9 classes\n",
      "ğŸ“ Characters: ['à¦…' 'à¦†' 'à¦‡' 'à¦‰' 'à¦‹' 'à¦' 'à¦' 'à¦“' 'à¦”']... (showing first 10)\n",
      "\n",
      "ğŸ‰ MODEL LOADING SUCCESSFUL!\n",
      "âœ… Ready for Bengali Sign Language recognition\n",
      "\n",
      "ğŸ“Š MODEL INFORMATION:\n",
      "   â€¢ Input shape: (None, 1, 10)\n",
      "   â€¢ Output classes: 9\n",
      "   â€¢ Model layers: 12\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“¦ Import Required Libraries and Load LSTM Model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import threading\n",
    "import requests\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "import json\n",
    "\n",
    "# TensorFlow/Keras imports\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras.models import load_model\n",
    "    from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "    import joblib\n",
    "    print(\"âœ… All required libraries imported successfully!\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ Import error: {e}\")\n",
    "    print(\"ğŸ“¦ Installing required packages...\")\n",
    "    !pip install tensorflow scikit-learn requests matplotlib\n",
    "\n",
    "# Load the trained LSTM model and preprocessing components\n",
    "def load_bengali_lstm_model():\n",
    "    \"\"\"Load the trained LSTM model and preprocessing components\"\"\"\n",
    "    \n",
    "    print(\"ğŸ”„ Loading Bengali Sign Language LSTM Model...\")\n",
    "    \n",
    "    try:\n",
    "        # Model paths\n",
    "        model_path = '/home/meraj/Downloads/BdSL_Bangla Sign_Language/sarborno_lstm_model.h5'\n",
    "        preprocessing_path = '/home/meraj/Downloads/BdSL_Bangla Sign_Language/sarborno_lstm_preprocessing.pkl'\n",
    "        \n",
    "        # Load LSTM model\n",
    "        print(\"ğŸ“‚ Loading LSTM model...\")\n",
    "        lstm_model = load_model(model_path)\n",
    "        print(f\"âœ… LSTM model loaded: {lstm_model.input_shape}\")\n",
    "        \n",
    "        # Load preprocessing components\n",
    "        print(\"ğŸ“‚ Loading preprocessing components...\")\n",
    "        preprocessing_components = joblib.load(preprocessing_path)\n",
    "        \n",
    "        scaler = preprocessing_components['scaler']\n",
    "        label_encoder = preprocessing_components['label_encoder']\n",
    "        \n",
    "        print(f\"âœ… Scaler loaded: {scaler.__class__.__name__}\")\n",
    "        print(f\"âœ… Label encoder loaded with {len(label_encoder.classes_)} classes\")\n",
    "        print(f\"ğŸ“ Characters: {label_encoder.classes_[:10]}... (showing first 10)\")\n",
    "        \n",
    "        return lstm_model, scaler, label_encoder\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error loading model: {e}\")\n",
    "        print(\"ğŸ’¡ Make sure the model files exist:\")\n",
    "        print(f\"   â€¢ {model_path}\")\n",
    "        print(f\"   â€¢ {preprocessing_path}\")\n",
    "        return None, None, None\n",
    "\n",
    "# Load the model\n",
    "print(\"ğŸš€ INITIALIZING BENGALI SIGN LANGUAGE RECOGNITION SYSTEM...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "lstm_model, scaler, label_encoder = load_bengali_lstm_model()\n",
    "\n",
    "if lstm_model is not None:\n",
    "    print(\"\\nğŸ‰ MODEL LOADING SUCCESSFUL!\")\n",
    "    print(\"âœ… Ready for Bengali Sign Language recognition\")\n",
    "    \n",
    "    # Display model summary\n",
    "    print(f\"\\nğŸ“Š MODEL INFORMATION:\")\n",
    "    print(f\"   â€¢ Input shape: {lstm_model.input_shape}\")\n",
    "    print(f\"   â€¢ Output classes: {len(label_encoder.classes_)}\")\n",
    "    print(f\"   â€¢ Model layers: {len(lstm_model.layers)}\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\nâŒ MODEL LOADING FAILED!\")\n",
    "    print(\"ğŸ’¡ Please ensure the model files are available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "60450b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ INITIALIZING ESP32 ACCESS POINT CLIENT...\n",
      "==================================================\n",
      "ğŸŒ ESP32AccessPointClient initialized\n",
      "   ğŸ“¡ Base URL: http://192.168.4.1:80\n",
      "   â±ï¸ Timeout: 5s\n",
      "ğŸ” Testing connection to ESP32 at http://192.168.4.1:80...\n",
      "âš ï¸ ESP32 responded with status: 404\n",
      "âš ï¸ ESP32 Access Point connection failed - will retry during operation\n"
     ]
    }
   ],
   "source": [
    "# ğŸŒ ESP32 Access Point HTTP Client\n",
    "class ESP32AccessPointClient:\n",
    "    \"\"\"\n",
    "    HTTP client for connecting to ESP32 in Access Point mode\n",
    "    Provides stable HTTP-based communication as alternative to WebSocket\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, esp32_ip=\"192.168.10.88\", port=80, timeout=5):\n",
    "        \"\"\"\n",
    "        Initialize ESP32 Access Point client\n",
    "        \n",
    "        Args:\n",
    "            esp32_ip: IP address of ESP32 Access Point (default: 192.168.10.88)\n",
    "            port: HTTP port (default: 80)\n",
    "            timeout: Request timeout in seconds\n",
    "        \"\"\"\n",
    "        self.esp32_ip = esp32_ip\n",
    "        self.port = port\n",
    "        self.base_url = f\"http://{esp32_ip}:{port}\"\n",
    "        self.timeout = timeout\n",
    "        self.session = requests.Session()\n",
    "        \n",
    "        # Connection statistics\n",
    "        self.stats = {\n",
    "            'total_requests': 0,\n",
    "            'successful_requests': 0,\n",
    "            'failed_requests': 0,\n",
    "            'connection_errors': 0,\n",
    "            'timeout_errors': 0,\n",
    "            'last_success_time': None,\n",
    "            'last_error_time': None\n",
    "        }\n",
    "        \n",
    "        print(f\"ğŸŒ ESP32AccessPointClient initialized\")\n",
    "        print(f\"   ğŸ“¡ Base URL: {self.base_url}\")\n",
    "        print(f\"   â±ï¸ Timeout: {timeout}s\")\n",
    "    \n",
    "    def test_connection(self):\n",
    "        \"\"\"Test connection to ESP32 Access Point\"\"\"\n",
    "        print(f\"ğŸ” Testing connection to ESP32 at {self.base_url}...\")\n",
    "        \n",
    "        try:\n",
    "            response = self.session.get(f\"{self.base_url}/status\", timeout=self.timeout)\n",
    "            if response.status_code == 200:\n",
    "                print(\"âœ… ESP32 Access Point connection successful!\")\n",
    "                return True\n",
    "            else:\n",
    "                print(f\"âš ï¸ ESP32 responded with status: {response.status_code}\")\n",
    "                return False\n",
    "                \n",
    "        except requests.exceptions.ConnectionError:\n",
    "            print(\"âŒ Connection error: Cannot reach ESP32\")\n",
    "            return False\n",
    "        except requests.exceptions.Timeout:\n",
    "            print(\"âŒ Timeout error: ESP32 not responding\")\n",
    "            return False\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Unexpected error: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def get_sensor_data(self, endpoint=\"/data\"):\n",
    "        \"\"\"\n",
    "        Fetch sensor data from ESP32 via HTTP GET request\n",
    "        \n",
    "        Args:\n",
    "            endpoint: API endpoint to fetch data from\n",
    "            \n",
    "        Returns:\n",
    "            dict: Sensor data or None if failed\n",
    "        \"\"\"\n",
    "        url = f\"{self.base_url}{endpoint}\"\n",
    "        \n",
    "        try:\n",
    "            self.stats['total_requests'] += 1\n",
    "            \n",
    "            response = self.session.get(url, timeout=self.timeout)\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                self.stats['successful_requests'] += 1\n",
    "                self.stats['last_success_time'] = time.time()\n",
    "                \n",
    "                # Try to parse as JSON\n",
    "                try:\n",
    "                    data = response.json()\n",
    "                    return data\n",
    "                except json.JSONDecodeError:\n",
    "                    # If not JSON, try to parse as CSV-like data\n",
    "                    text_data = response.text.strip()\n",
    "                    if text_data:\n",
    "                        return self._parse_csv_data(text_data)\n",
    "                    return None\n",
    "                    \n",
    "            else:\n",
    "                self.stats['failed_requests'] += 1\n",
    "                print(f\"âš ï¸ HTTP {response.status_code}: {response.text[:100]}\")\n",
    "                return None\n",
    "                \n",
    "        except requests.exceptions.ConnectionError:\n",
    "            self.stats['connection_errors'] += 1\n",
    "            self.stats['last_error_time'] = time.time()\n",
    "            return None\n",
    "            \n",
    "        except requests.exceptions.Timeout:\n",
    "            self.stats['timeout_errors'] += 1\n",
    "            self.stats['last_error_time'] = time.time()\n",
    "            return None\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.stats['failed_requests'] += 1\n",
    "            self.stats['last_error_time'] = time.time()\n",
    "            print(f\"âŒ Error fetching data: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def _parse_csv_data(self, csv_text):\n",
    "        \"\"\"\n",
    "        Parse CSV-formatted sensor data from ESP32\n",
    "        \n",
    "        Args:\n",
    "            csv_text: Raw CSV text data\n",
    "            \n",
    "        Returns:\n",
    "            dict: Parsed sensor data\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Split by lines and take the last non-empty line\n",
    "            lines = [line.strip() for line in csv_text.split('\\n') if line.strip()]\n",
    "            if not lines:\n",
    "                return None\n",
    "            \n",
    "            # Take the most recent data (last line)\n",
    "            data_line = lines[-1]\n",
    "            \n",
    "            # Split by comma and convert to float\n",
    "            values = [float(x.strip()) for x in data_line.split(',')]\n",
    "            \n",
    "            # Create structured data (assuming 6 sensor values)\n",
    "            if len(values) >= 6:\n",
    "                return {\n",
    "                    'timestamp': time.time(),\n",
    "                    'sensor_data': values,\n",
    "                    'sensor_count': len(values)\n",
    "                }\n",
    "            else:\n",
    "                print(f\"âš ï¸ Incomplete data: expected 6+ values, got {len(values)}\")\n",
    "                return None\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error parsing CSV data: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def get_connection_stats(self):\n",
    "        \"\"\"Get connection statistics\"\"\"\n",
    "        success_rate = 0\n",
    "        if self.stats['total_requests'] > 0:\n",
    "            success_rate = (self.stats['successful_requests'] / self.stats['total_requests']) * 100\n",
    "        \n",
    "        return {\n",
    "            **self.stats,\n",
    "            'success_rate': success_rate,\n",
    "            'connection_reliability': 'High' if success_rate >= 90 else 'Medium' if success_rate >= 70 else 'Low'\n",
    "        }\n",
    "    \n",
    "    def print_stats(self):\n",
    "        \"\"\"Print connection statistics\"\"\"\n",
    "        stats = self.get_connection_stats()\n",
    "        \n",
    "        print(f\"\\nğŸ“Š ESP32 ACCESS POINT CONNECTION STATISTICS:\")\n",
    "        print(f\"   ğŸ“ˆ Total requests: {stats['total_requests']}\")\n",
    "        print(f\"   âœ… Successful: {stats['successful_requests']}\")\n",
    "        print(f\"   âŒ Failed: {stats['failed_requests']}\")\n",
    "        print(f\"   ğŸ”— Connection errors: {stats['connection_errors']}\")\n",
    "        print(f\"   â±ï¸ Timeout errors: {stats['timeout_errors']}\")\n",
    "        print(f\"   ğŸ“Š Success rate: {stats['success_rate']:.1f}%\")\n",
    "        print(f\"   ğŸ¯ Reliability: {stats['connection_reliability']}\")\n",
    "        \n",
    "        if stats['last_success_time']:\n",
    "            last_success = time.time() - stats['last_success_time']\n",
    "            print(f\"   ğŸ•’ Last success: {last_success:.1f}s ago\")\n",
    "\n",
    "# Initialize ESP32 Access Point Client\n",
    "print(\"ğŸš€ INITIALIZING ESP32 ACCESS POINT CLIENT...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "esp32_client = ESP32AccessPointClient(esp32_ip=\"192.168.4.1\", port=80, timeout=5)\n",
    "\n",
    "# Test connection\n",
    "if esp32_client.test_connection():\n",
    "    print(\"ğŸ‰ ESP32 Access Point ready for data communication!\")\n",
    "else:\n",
    "    print(\"âš ï¸ ESP32 Access Point connection failed - will retry during operation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a2137149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ INITIALIZING BENGALI PREDICTOR WITH ACCESS POINT...\n",
      "=======================================================\n",
      "ğŸ§  AccessPointBengaliPredictor initialized\n",
      "   ğŸ“Š Model input shape: (None, 1, 10)\n",
      "   ğŸ“ Sequence length: 1\n",
      "   ğŸ¯ Features per step: 10\n",
      "   ğŸ”¤ Character classes: 9\n",
      "ğŸ‰ Bengali predictor ready for Access Point communication!\n"
     ]
    }
   ],
   "source": [
    "# ğŸ§  Bengali Sign Language LSTM Predictor for Access Point\n",
    "class AccessPointBengaliPredictor:\n",
    "    \"\"\"\n",
    "    Bengali Sign Language predictor using LSTM model with ESP32 Access Point data\n",
    "    Provides real-time prediction capabilities with HTTP-based communication\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, lstm_model, scaler, label_encoder, esp32_client):\n",
    "        \"\"\"\n",
    "        Initialize the predictor\n",
    "        \n",
    "        Args:\n",
    "            lstm_model: Trained LSTM model\n",
    "            scaler: Data scaler for preprocessing\n",
    "            label_encoder: Label encoder for character mapping\n",
    "            esp32_client: ESP32AccessPointClient instance\n",
    "        \"\"\"\n",
    "        self.lstm_model = lstm_model\n",
    "        self.scaler = scaler\n",
    "        self.label_encoder = label_encoder\n",
    "        self.esp32_client = esp32_client\n",
    "        \n",
    "        # Get model input requirements\n",
    "        self.input_shape = lstm_model.input_shape\n",
    "        self.sequence_length = self.input_shape[1]  # Time steps\n",
    "        self.feature_count = self.input_shape[2]    # Features per time step\n",
    "        \n",
    "        # Data buffer for sequence building\n",
    "        self.data_buffer = deque(maxlen=self.sequence_length)\n",
    "        \n",
    "        # Prediction statistics\n",
    "        self.prediction_stats = {\n",
    "            'total_predictions': 0,\n",
    "            'successful_predictions': 0,\n",
    "            'confident_predictions': 0,\n",
    "            'data_fetch_attempts': 0,\n",
    "            'data_fetch_successes': 0,\n",
    "            'last_prediction_time': None,\n",
    "            'last_character': None,\n",
    "            'last_confidence': None\n",
    "        }\n",
    "        \n",
    "        print(f\"ğŸ§  AccessPointBengaliPredictor initialized\")\n",
    "        print(f\"   ğŸ“Š Model input shape: {self.input_shape}\")\n",
    "        print(f\"   ğŸ“ Sequence length: {self.sequence_length}\")\n",
    "        print(f\"   ğŸ¯ Features per step: {self.feature_count}\")\n",
    "        print(f\"   ğŸ”¤ Character classes: {len(self.label_encoder.classes_)}\")\n",
    "    \n",
    "    def fetch_and_predict(self, confidence_threshold=0.8):\n",
    "        \"\"\"\n",
    "        Fetch data from ESP32 and make prediction\n",
    "        \n",
    "        Args:\n",
    "            confidence_threshold: Minimum confidence for valid prediction\n",
    "            \n",
    "        Returns:\n",
    "            dict: Prediction result with character, confidence, and status\n",
    "        \"\"\"\n",
    "        self.prediction_stats['data_fetch_attempts'] += 1\n",
    "        \n",
    "        # Fetch sensor data from ESP32\n",
    "        sensor_data = self.esp32_client.get_sensor_data()\n",
    "        \n",
    "        if sensor_data is None:\n",
    "            return {\n",
    "                'success': False,\n",
    "                'error': 'Failed to fetch data from ESP32',\n",
    "                'character': None,\n",
    "                'confidence': None,\n",
    "                'timestamp': time.time()\n",
    "            }\n",
    "        \n",
    "        self.prediction_stats['data_fetch_successes'] += 1\n",
    "        \n",
    "        # Extract sensor values\n",
    "        if 'sensor_data' in sensor_data:\n",
    "            sensor_values = sensor_data['sensor_data']\n",
    "        else:\n",
    "            return {\n",
    "                'success': False,\n",
    "                'error': 'Invalid sensor data format',\n",
    "                'character': None,\n",
    "                'confidence': None,\n",
    "                'timestamp': time.time()\n",
    "            }\n",
    "        \n",
    "        # Ensure we have enough features\n",
    "        if len(sensor_values) < self.feature_count:\n",
    "            return {\n",
    "                'success': False,\n",
    "                'error': f'Insufficient features: got {len(sensor_values)}, need {self.feature_count}',\n",
    "                'character': None,\n",
    "                'confidence': None,\n",
    "                'timestamp': time.time()\n",
    "            }\n",
    "        \n",
    "        # Take only the required number of features\n",
    "        features = sensor_values[:self.feature_count]\n",
    "        \n",
    "        # Add to buffer\n",
    "        self.data_buffer.append(features)\n",
    "        \n",
    "        # Check if we have enough data for prediction\n",
    "        if len(self.data_buffer) < self.sequence_length:\n",
    "            return {\n",
    "                'success': False,\n",
    "                'error': f'Building sequence: {len(self.data_buffer)}/{self.sequence_length}',\n",
    "                'character': None,\n",
    "                'confidence': None,\n",
    "                'timestamp': time.time(),\n",
    "                'buffer_progress': len(self.data_buffer) / self.sequence_length\n",
    "            }\n",
    "        \n",
    "        # Make prediction\n",
    "        try:\n",
    "            # Prepare data for prediction\n",
    "            sequence_data = np.array(list(self.data_buffer))\n",
    "            sequence_data_scaled = self.scaler.transform(sequence_data)\n",
    "            prediction_input = sequence_data_scaled.reshape(1, self.sequence_length, self.feature_count)\n",
    "            \n",
    "            # Get prediction\n",
    "            prediction_probs = self.lstm_model.predict(prediction_input, verbose=0)\n",
    "            predicted_class_idx = np.argmax(prediction_probs[0])\n",
    "            confidence = float(prediction_probs[0][predicted_class_idx])\n",
    "            \n",
    "            # Decode character\n",
    "            predicted_character = self.label_encoder.inverse_transform([predicted_class_idx])[0]\n",
    "            \n",
    "            # Update statistics\n",
    "            self.prediction_stats['total_predictions'] += 1\n",
    "            self.prediction_stats['last_prediction_time'] = time.time()\n",
    "            self.prediction_stats['last_character'] = predicted_character\n",
    "            self.prediction_stats['last_confidence'] = confidence\n",
    "            \n",
    "            if confidence >= confidence_threshold:\n",
    "                self.prediction_stats['confident_predictions'] += 1\n",
    "                self.prediction_stats['successful_predictions'] += 1\n",
    "                \n",
    "                return {\n",
    "                    'success': True,\n",
    "                    'character': predicted_character,\n",
    "                    'confidence': confidence,\n",
    "                    'timestamp': time.time(),\n",
    "                    'is_confident': True,\n",
    "                    'sensor_data': features\n",
    "                }\n",
    "            else:\n",
    "                return {\n",
    "                    'success': True,\n",
    "                    'character': predicted_character,\n",
    "                    'confidence': confidence,\n",
    "                    'timestamp': time.time(),\n",
    "                    'is_confident': False,\n",
    "                    'warning': f'Low confidence: {confidence:.3f} < {confidence_threshold}',\n",
    "                    'sensor_data': features\n",
    "                }\n",
    "                \n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'success': False,\n",
    "                'error': f'Prediction error: {e}',\n",
    "                'character': None,\n",
    "                'confidence': None,\n",
    "                'timestamp': time.time()\n",
    "            }\n",
    "    \n",
    "    def get_prediction_stats(self):\n",
    "        \"\"\"Get prediction statistics\"\"\"\n",
    "        stats = self.prediction_stats.copy()\n",
    "        \n",
    "        # Calculate rates\n",
    "        if stats['data_fetch_attempts'] > 0:\n",
    "            stats['data_fetch_rate'] = (stats['data_fetch_successes'] / stats['data_fetch_attempts']) * 100\n",
    "        else:\n",
    "            stats['data_fetch_rate'] = 0\n",
    "        \n",
    "        if stats['total_predictions'] > 0:\n",
    "            stats['confidence_rate'] = (stats['confident_predictions'] / stats['total_predictions']) * 100\n",
    "            stats['success_rate'] = (stats['successful_predictions'] / stats['total_predictions']) * 100\n",
    "        else:\n",
    "            stats['confidence_rate'] = 0\n",
    "            stats['success_rate'] = 0\n",
    "        \n",
    "        return stats\n",
    "    \n",
    "    def print_stats(self):\n",
    "        \"\"\"Print prediction statistics\"\"\"\n",
    "        stats = self.get_prediction_stats()\n",
    "        \n",
    "        print(f\"\\nğŸ§  BENGALI PREDICTOR STATISTICS:\")\n",
    "        print(f\"   ğŸ“¡ Data fetch attempts: {stats['data_fetch_attempts']}\")\n",
    "        print(f\"   âœ… Data fetch successes: {stats['data_fetch_successes']}\")\n",
    "        print(f\"   ğŸ“Š Data fetch rate: {stats['data_fetch_rate']:.1f}%\")\n",
    "        print(f\"   ğŸ¯ Total predictions: {stats['total_predictions']}\")\n",
    "        print(f\"   âœ¨ Confident predictions: {stats['confident_predictions']}\")\n",
    "        print(f\"   ğŸ“ˆ Confidence rate: {stats['confidence_rate']:.1f}%\")\n",
    "        print(f\"   ğŸ‰ Success rate: {stats['success_rate']:.1f}%\")\n",
    "        \n",
    "        if stats['last_character']:\n",
    "            print(f\"   ğŸ”¤ Last character: {stats['last_character']}\")\n",
    "            print(f\"   ğŸ’ª Last confidence: {stats['last_confidence']:.3f}\")\n",
    "\n",
    "# Initialize Bengali Predictor (only if model is loaded)\n",
    "if lstm_model is not None and scaler is not None and label_encoder is not None:\n",
    "    print(\"ğŸš€ INITIALIZING BENGALI PREDICTOR WITH ACCESS POINT...\")\n",
    "    print(\"=\" * 55)\n",
    "    \n",
    "    bengali_predictor = AccessPointBengaliPredictor(\n",
    "        lstm_model=lstm_model,\n",
    "        scaler=scaler,\n",
    "        label_encoder=label_encoder,\n",
    "        esp32_client=esp32_client\n",
    "    )\n",
    "    \n",
    "    print(\"ğŸ‰ Bengali predictor ready for Access Point communication!\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ Cannot initialize predictor - model components not loaded\")\n",
    "    bengali_predictor = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b1989585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Running single prediction test...\n",
      "ğŸ¯ TESTING SINGLE PREDICTION FROM ESP32 ACCESS POINT...\n",
      "=======================================================\n",
      "âš ï¸ HTTP 404: Not found\n",
      "â° Timestamp: 00:46:03\n",
      "âŒ FAILED: Failed to fetch data from ESP32\n"
     ]
    }
   ],
   "source": [
    "# ğŸ¯ Single Prediction Test\n",
    "def test_single_prediction(show_details=True):\n",
    "    \"\"\"Test a single prediction from ESP32 Access Point\"\"\"\n",
    "    \n",
    "    if bengali_predictor is None:\n",
    "        print(\"âŒ Predictor not available\")\n",
    "        return\n",
    "    \n",
    "    print(\"ğŸ¯ TESTING SINGLE PREDICTION FROM ESP32 ACCESS POINT...\")\n",
    "    print(\"=\" * 55)\n",
    "    \n",
    "    result = bengali_predictor.fetch_and_predict(confidence_threshold=0.7)\n",
    "    \n",
    "    if show_details:\n",
    "        print(f\"â° Timestamp: {time.strftime('%H:%M:%S', time.localtime(result['timestamp']))}\")\n",
    "        \n",
    "        if result['success']:\n",
    "            if result.get('is_confident', False):\n",
    "                print(f\"ğŸ‰ SUCCESS: Predicted '{result['character']}' with {result['confidence']:.1%} confidence\")\n",
    "            else:\n",
    "                print(f\"âš ï¸ LOW CONFIDENCE: '{result['character']}' ({result['confidence']:.1%})\")\n",
    "                if 'warning' in result:\n",
    "                    print(f\"   ğŸ’¡ {result['warning']}\")\n",
    "        else:\n",
    "            print(f\"âŒ FAILED: {result['error']}\")\n",
    "            if 'buffer_progress' in result:\n",
    "                progress = result['buffer_progress'] * 100\n",
    "                print(f\"   ğŸ“Š Buffer progress: {progress:.1f}%\")\n",
    "        \n",
    "        # Show sensor data if available\n",
    "        if 'sensor_data' in result:\n",
    "            sensor_summary = [f\"{x:.2f}\" for x in result['sensor_data'][:3]]\n",
    "            print(f\"   ğŸ“¡ Sensor data: [{', '.join(sensor_summary)}...]\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Test the prediction\n",
    "if bengali_predictor is not None:\n",
    "    print(\"ğŸ” Running single prediction test...\")\n",
    "    test_result = test_single_prediction()\n",
    "else:\n",
    "    print(\"âš ï¸ Cannot test - predictor not initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9645452c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ INITIALIZING CONTINUOUS ACCESS POINT PREDICTOR...\n",
      "=======================================================\n",
      "ğŸ”„ ContinuousAccessPointPredictor initialized\n",
      "   â±ï¸ Polling interval: 0.2s (5.0 Hz)\n",
      "ğŸ‰ Continuous predictor ready!\n",
      "ğŸ’¡ Use: continuous_predictor.start_continuous_prediction(duration_seconds=30)\n"
     ]
    }
   ],
   "source": [
    "# ğŸ”„ Continuous Real-Time Prediction with Access Point\n",
    "class ContinuousAccessPointPredictor:\n",
    "    \"\"\"\n",
    "    Continuous prediction system using ESP32 Access Point\n",
    "    Provides real-time Bengali Sign Language recognition with HTTP polling\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, bengali_predictor, polling_interval=0.2):\n",
    "        \"\"\"\n",
    "        Initialize continuous predictor\n",
    "        \n",
    "        Args:\n",
    "            bengali_predictor: AccessPointBengaliPredictor instance\n",
    "            polling_interval: Time between HTTP requests (seconds)\n",
    "        \"\"\"\n",
    "        self.bengali_predictor = bengali_predictor\n",
    "        self.polling_interval = polling_interval\n",
    "        self.is_running = False\n",
    "        self.thread = None\n",
    "        \n",
    "        # Results tracking\n",
    "        self.results_history = deque(maxlen=100)\n",
    "        self.session_stats = {\n",
    "            'start_time': None,\n",
    "            'total_polls': 0,\n",
    "            'successful_predictions': 0,\n",
    "            'confident_predictions': 0,\n",
    "            'http_errors': 0,\n",
    "            'prediction_errors': 0,\n",
    "            'characters_detected': set(),\n",
    "            'latest_character': None,\n",
    "            'latest_confidence': None\n",
    "        }\n",
    "        \n",
    "        print(f\"ğŸ”„ ContinuousAccessPointPredictor initialized\")\n",
    "        print(f\"   â±ï¸ Polling interval: {polling_interval}s ({1/polling_interval:.1f} Hz)\")\n",
    "    \n",
    "    def start_continuous_prediction(self, duration_seconds=30, confidence_threshold=0.8):\n",
    "        \"\"\"\n",
    "        Start continuous prediction for specified duration\n",
    "        \n",
    "        Args:\n",
    "            duration_seconds: How long to run prediction (seconds)\n",
    "            confidence_threshold: Minimum confidence for valid predictions\n",
    "        \"\"\"\n",
    "        if self.is_running:\n",
    "            print(\"âš ï¸ Continuous prediction already running!\")\n",
    "            return\n",
    "        \n",
    "        print(f\"ğŸš€ STARTING CONTINUOUS PREDICTION...\")\n",
    "        print(f\"   â° Duration: {duration_seconds}s\")\n",
    "        print(f\"   ğŸ¯ Confidence threshold: {confidence_threshold}\")\n",
    "        print(f\"   ğŸ“¡ Polling rate: {1/self.polling_interval:.1f} Hz\")\n",
    "        print(\"   ğŸ›‘ Press Ctrl+C to stop early\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        self.is_running = True\n",
    "        self.session_stats['start_time'] = time.time()\n",
    "        \n",
    "        def prediction_loop():\n",
    "            try:\n",
    "                end_time = time.time() + duration_seconds\n",
    "                \n",
    "                while self.is_running and time.time() < end_time:\n",
    "                    loop_start = time.time()\n",
    "                    \n",
    "                    # Make prediction\n",
    "                    self.session_stats['total_polls'] += 1\n",
    "                    result = self.bengali_predictor.fetch_and_predict(confidence_threshold)\n",
    "                    \n",
    "                    # Process result\n",
    "                    self._process_prediction_result(result, confidence_threshold)\n",
    "                    \n",
    "                    # Store in history\n",
    "                    self.results_history.append({\n",
    "                        'timestamp': time.time(),\n",
    "                        'result': result,\n",
    "                        'poll_number': self.session_stats['total_polls']\n",
    "                    })\n",
    "                    \n",
    "                    # Display result\n",
    "                    self._display_prediction_result(result)\n",
    "                    \n",
    "                    # Maintain polling rate\n",
    "                    elapsed = time.time() - loop_start\n",
    "                    sleep_time = max(0, self.polling_interval - elapsed)\n",
    "                    if sleep_time > 0:\n",
    "                        time.sleep(sleep_time)\n",
    "                \n",
    "                print(\"\\\\nâœ… Continuous prediction completed!\")\n",
    "                \n",
    "            except KeyboardInterrupt:\n",
    "                print(\"\\\\nğŸ›‘ Prediction stopped by user\")\n",
    "            except Exception as e:\n",
    "                print(f\"\\\\nâŒ Error in prediction loop: {e}\")\n",
    "            finally:\n",
    "                self.is_running = False\n",
    "        \n",
    "        # Start prediction in thread\n",
    "        self.thread = threading.Thread(target=prediction_loop, daemon=True)\n",
    "        self.thread.start()\n",
    "        \n",
    "        return self.thread\n",
    "    \n",
    "    def _process_prediction_result(self, result, confidence_threshold):\n",
    "        \"\"\"Process and categorize prediction result\"\"\"\n",
    "        if result['success']:\n",
    "            self.session_stats['successful_predictions'] += 1\n",
    "            \n",
    "            if result.get('is_confident', False):\n",
    "                self.session_stats['confident_predictions'] += 1\n",
    "                self.session_stats['characters_detected'].add(result['character'])\n",
    "                self.session_stats['latest_character'] = result['character']\n",
    "                self.session_stats['latest_confidence'] = result['confidence']\n",
    "            \n",
    "        else:\n",
    "            if 'Failed to fetch data' in result.get('error', ''):\n",
    "                self.session_stats['http_errors'] += 1\n",
    "            else:\n",
    "                self.session_stats['prediction_errors'] += 1\n",
    "    \n",
    "    def _display_prediction_result(self, result):\n",
    "        \"\"\"Display prediction result in real-time\"\"\"\n",
    "        timestamp = time.strftime('%H:%M:%S', time.localtime(result['timestamp']))\n",
    "        poll_num = self.session_stats['total_polls']\n",
    "        \n",
    "        if result['success']:\n",
    "            char = result['character']\n",
    "            conf = result['confidence']\n",
    "            \n",
    "            if result.get('is_confident', False):\n",
    "                print(f\"[{timestamp}] Poll #{poll_num:3d}: âœ… '{char}' ({conf:.1%})\")\n",
    "            else:\n",
    "                print(f\"[{timestamp}] Poll #{poll_num:3d}: âš ï¸ '{char}' ({conf:.1%}) - Low confidence\")\n",
    "        else:\n",
    "            error = result['error']\n",
    "            if 'Building sequence' in error:\n",
    "                progress = result.get('buffer_progress', 0) * 100\n",
    "                print(f\"[{timestamp}] Poll #{poll_num:3d}: ğŸ“Š Building buffer... {progress:.0f}%\")\n",
    "            else:\n",
    "                print(f\"[{timestamp}] Poll #{poll_num:3d}: âŒ {error}\")\n",
    "    \n",
    "    def stop_prediction(self):\n",
    "        \"\"\"Stop continuous prediction\"\"\"\n",
    "        if self.is_running:\n",
    "            self.is_running = False\n",
    "            print(\"ğŸ›‘ Stopping continuous prediction...\")\n",
    "            if self.thread:\n",
    "                self.thread.join(timeout=2)\n",
    "            print(\"âœ… Prediction stopped\")\n",
    "        else:\n",
    "            print(\"â„¹ï¸ Prediction not running\")\n",
    "    \n",
    "    def get_session_summary(self):\n",
    "        \"\"\"Get summary of current prediction session\"\"\"\n",
    "        if self.session_stats['start_time'] is None:\n",
    "            return None\n",
    "        \n",
    "        elapsed = time.time() - self.session_stats['start_time']\n",
    "        stats = self.session_stats.copy()\n",
    "        \n",
    "        # Calculate rates\n",
    "        if stats['total_polls'] > 0:\n",
    "            stats['success_rate'] = (stats['successful_predictions'] / stats['total_polls']) * 100\n",
    "            stats['confidence_rate'] = (stats['confident_predictions'] / stats['total_polls']) * 100\n",
    "            stats['polling_rate'] = stats['total_polls'] / elapsed if elapsed > 0 else 0\n",
    "        else:\n",
    "            stats['success_rate'] = 0\n",
    "            stats['confidence_rate'] = 0\n",
    "            stats['polling_rate'] = 0\n",
    "        \n",
    "        stats['elapsed_time'] = elapsed\n",
    "        stats['characters_detected'] = list(stats['characters_detected'])\n",
    "        \n",
    "        return stats\n",
    "    \n",
    "    def print_session_summary(self):\n",
    "        \"\"\"Print detailed session summary\"\"\"\n",
    "        summary = self.get_session_summary()\n",
    "        \n",
    "        if summary is None:\n",
    "            print(\"ğŸ“Š No session data available\")\n",
    "            return\n",
    "        \n",
    "        print(f\"\\\\nğŸ“Š CONTINUOUS PREDICTION SESSION SUMMARY:\")\n",
    "        print(f\"   â° Duration: {summary['elapsed_time']:.1f}s\")\n",
    "        print(f\"   ğŸ“¡ Total polls: {summary['total_polls']}\")\n",
    "        print(f\"   ğŸ“ˆ Polling rate: {summary['polling_rate']:.1f} Hz\")\n",
    "        print(f\"   âœ… Successful predictions: {summary['successful_predictions']}\")\n",
    "        print(f\"   ğŸ’ª Confident predictions: {summary['confident_predictions']}\")\n",
    "        print(f\"   ğŸŒ HTTP errors: {summary['http_errors']}\")\n",
    "        print(f\"   ğŸ¤– Prediction errors: {summary['prediction_errors']}\")\n",
    "        print(f\"   ğŸ“Š Success rate: {summary['success_rate']:.1f}%\")\n",
    "        print(f\"   ğŸ¯ Confidence rate: {summary['confidence_rate']:.1f}%\")\n",
    "        \n",
    "        if summary['characters_detected']:\n",
    "            print(f\"   ğŸ”¤ Characters detected: {', '.join(summary['characters_detected'])}\")\n",
    "        \n",
    "        if summary['latest_character']:\n",
    "            print(f\"   ğŸ† Latest prediction: '{summary['latest_character']}' ({summary['latest_confidence']:.1%})\")\n",
    "\n",
    "# Initialize continuous predictor\n",
    "if bengali_predictor is not None:\n",
    "    print(\"ğŸš€ INITIALIZING CONTINUOUS ACCESS POINT PREDICTOR...\")\n",
    "    print(\"=\" * 55)\n",
    "    \n",
    "    continuous_predictor = ContinuousAccessPointPredictor(\n",
    "        bengali_predictor=bengali_predictor,\n",
    "        polling_interval=0.2  # 5 Hz polling rate\n",
    "    )\n",
    "    \n",
    "    print(\"ğŸ‰ Continuous predictor ready!\")\n",
    "    print(\"ğŸ’¡ Use: continuous_predictor.start_continuous_prediction(duration_seconds=30)\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ Cannot initialize continuous predictor - Bengali predictor not available\")\n",
    "    continuous_predictor = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "75610aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‰ ACCESS POINT IMPLEMENTATION READY!\n",
      "========================================\n",
      "ğŸ’¡ Available functions:\n",
      "   â€¢ test_single_prediction() - Test one prediction\n",
      "   â€¢ continuous_predictor.start_continuous_prediction(30) - 30s continuous\n",
      "   â€¢ demo_access_point_recognition(20) - 20s complete demo\n",
      "   â€¢ esp32_client.print_stats() - Connection statistics\n",
      "   â€¢ bengali_predictor.print_stats() - Prediction statistics\n",
      "\n",
      "ğŸš€ Quick start: demo_access_point_recognition(20)\n"
     ]
    }
   ],
   "source": [
    "# ğŸš€ Quick Start Demo - ESP32 Access Point Bengali Recognition\n",
    "def demo_access_point_recognition(duration=20):\n",
    "    \"\"\"\n",
    "    Quick demonstration of ESP32 Access Point Bengali Sign Language recognition\n",
    "    \n",
    "    Args:\n",
    "        duration: Demo duration in seconds\n",
    "    \"\"\"\n",
    "    print(\"ğŸš€ ESP32 ACCESS POINT BENGALI RECOGNITION DEMO\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    if continuous_predictor is None:\n",
    "        print(\"âŒ Continuous predictor not available\")\n",
    "        return\n",
    "    \n",
    "    # Check ESP32 connection\n",
    "    print(\"ğŸ” Checking ESP32 Access Point connection...\")\n",
    "    if not esp32_client.test_connection():\n",
    "        print(\"âš ï¸ ESP32 connection failed, but continuing with demo...\")\n",
    "        print(\"ğŸ’¡ Make sure ESP32 is in Access Point mode at 192.168.10.88\")\n",
    "    \n",
    "    print(f\"\\\\nğŸ¬ Starting {duration}s demo...\")\n",
    "    print(\"ğŸ“± Move your glove to perform Bengali sign gestures\")\n",
    "    print(\"ğŸ¯ System will recognize characters with HTTP polling\")\n",
    "    print(\"ğŸ›‘ Press Ctrl+C to stop early\")\n",
    "    \n",
    "    # Start continuous prediction\n",
    "    thread = continuous_predictor.start_continuous_prediction(\n",
    "        duration_seconds=duration,\n",
    "        confidence_threshold=0.75\n",
    "    )\n",
    "    \n",
    "    # Wait for completion\n",
    "    if thread:\n",
    "        try:\n",
    "            thread.join()\n",
    "        except KeyboardInterrupt:\n",
    "            continuous_predictor.stop_prediction()\n",
    "    \n",
    "    # Show final statistics\n",
    "    print(\"\\\\n\" + \"=\" * 50)\n",
    "    continuous_predictor.print_session_summary()\n",
    "    \n",
    "    # Show connection stats\n",
    "    esp32_client.print_stats()\n",
    "    \n",
    "    # Show predictor stats\n",
    "    bengali_predictor.print_stats()\n",
    "\n",
    "print(\"ğŸ‰ ACCESS POINT IMPLEMENTATION READY!\")\n",
    "print(\"=\" * 40)\n",
    "print(\"ğŸ’¡ Available functions:\")\n",
    "print(\"   â€¢ test_single_prediction() - Test one prediction\")\n",
    "print(\"   â€¢ continuous_predictor.start_continuous_prediction(30) - 30s continuous\")\n",
    "print(\"   â€¢ demo_access_point_recognition(20) - 20s complete demo\")\n",
    "print(\"   â€¢ esp32_client.print_stats() - Connection statistics\")\n",
    "print(\"   â€¢ bengali_predictor.print_stats() - Prediction statistics\")\n",
    "print()\n",
    "print(\"ğŸš€ Quick start: demo_access_point_recognition(20)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c7063218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This entire pipeline works offline:\n",
    "def offline_bengali_recognition():\n",
    "    \"\"\"Complete offline Bengali sign recognition\"\"\"\n",
    "    \n",
    "    # 1. ESP32 provides local WiFi (no internet)\n",
    "    esp32_client = ESP32AccessPointClient(\"192.168.4.1\")\n",
    "    \n",
    "    # 2. Get sensor data via local WiFi\n",
    "    sensor_data = esp32_client.get_sensor_data()\n",
    "    \n",
    "    # 3. AI prediction happens locally\n",
    "    result = bengali_predictor.fetch_and_predict()\n",
    "    \n",
    "    # 4. Bengali character recognized offline!\n",
    "    return result['character']  # e.g., 'à¦…', 'à¦†', 'à¦‡'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "66df09c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ INITIALIZING ENHANCED CONTINUOUS PREDICTOR...\n",
      "=======================================================\n",
      "ğŸ“ˆ EnhancedContinuousPredictor initialized\n",
      "   âš¡ Polling rate: 5.0 Hz\n",
      "   ğŸ’¾ History buffer: 200 samples\n",
      "ğŸ‰ Enhanced continuous predictor ready!\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“ˆ Enhanced Continuous Data Prediction with Real-Time Monitoring\n",
    "class EnhancedContinuousPredictor:\n",
    "    \"\"\"\n",
    "    Advanced continuous prediction system with real-time data visualization\n",
    "    and comprehensive monitoring capabilities\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, bengali_predictor, polling_interval=0.2):\n",
    "        \"\"\"\n",
    "        Initialize enhanced continuous predictor\n",
    "        \n",
    "        Args:\n",
    "            bengali_predictor: AccessPointBengaliPredictor instance\n",
    "            polling_interval: Time between predictions (seconds)\n",
    "        \"\"\"\n",
    "        self.bengali_predictor = bengali_predictor\n",
    "        self.polling_interval = polling_interval\n",
    "        self.is_running = False\n",
    "        self.thread = None\n",
    "        \n",
    "        # Enhanced data tracking\n",
    "        self.prediction_history = deque(maxlen=200)  # Store more history\n",
    "        self.confidence_history = deque(maxlen=200)\n",
    "        self.sensor_data_history = deque(maxlen=200)\n",
    "        self.timestamp_history = deque(maxlen=200)\n",
    "        \n",
    "        # Real-time statistics\n",
    "        self.live_stats = {\n",
    "            'start_time': None,\n",
    "            'total_predictions': 0,\n",
    "            'successful_predictions': 0,\n",
    "            'confident_predictions': 0,\n",
    "            'average_confidence': 0.0,\n",
    "            'prediction_rate': 0.0,\n",
    "            'characters_this_session': {},\n",
    "            'current_character': None,\n",
    "            'current_confidence': 0.0,\n",
    "            'last_update_time': None,\n",
    "            'data_quality_score': 0.0\n",
    "        }\n",
    "        \n",
    "        # Performance metrics\n",
    "        self.performance_metrics = {\n",
    "            'prediction_times': deque(maxlen=50),\n",
    "            'network_latencies': deque(maxlen=50),\n",
    "            'cpu_usage_samples': deque(maxlen=50),\n",
    "            'memory_usage_samples': deque(maxlen=50)\n",
    "        }\n",
    "        \n",
    "        print(f\"ğŸ“ˆ EnhancedContinuousPredictor initialized\")\n",
    "        print(f\"   âš¡ Polling rate: {1/polling_interval:.1f} Hz\")\n",
    "        print(f\"   ğŸ’¾ History buffer: {self.prediction_history.maxlen} samples\")\n",
    "    \n",
    "    def start_enhanced_prediction(self, duration_seconds=60, confidence_threshold=0.8, \n",
    "                                show_live_stats=True, update_interval=2.0):\n",
    "        \"\"\"\n",
    "        Start enhanced continuous prediction with live monitoring\n",
    "        \n",
    "        Args:\n",
    "            duration_seconds: Prediction duration\n",
    "            confidence_threshold: Minimum confidence for valid predictions\n",
    "            show_live_stats: Whether to show live statistics updates\n",
    "            update_interval: How often to update live stats (seconds)\n",
    "        \"\"\"\n",
    "        if self.is_running:\n",
    "            print(\"âš ï¸ Enhanced prediction already running!\")\n",
    "            return\n",
    "        \n",
    "        print(\"ğŸš€ STARTING ENHANCED CONTINUOUS PREDICTION...\")\n",
    "        print(f\"   â° Duration: {duration_seconds}s\")\n",
    "        print(f\"   ğŸ¯ Confidence threshold: {confidence_threshold:.1%}\")\n",
    "        print(f\"   ğŸ“¡ Polling rate: {1/self.polling_interval:.1f} Hz\")\n",
    "        print(f\"   ğŸ“Š Live stats: {'Enabled' if show_live_stats else 'Disabled'}\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        self.is_running = True\n",
    "        self.live_stats['start_time'] = time.time()\n",
    "        last_stats_update = time.time()\n",
    "        \n",
    "        def enhanced_prediction_loop():\n",
    "            try:\n",
    "                end_time = time.time() + duration_seconds\n",
    "                \n",
    "                while self.is_running and time.time() < end_time:\n",
    "                    loop_start = time.time()\n",
    "                    \n",
    "                    # Make prediction with timing\n",
    "                    prediction_start = time.time()\n",
    "                    result = self.bengali_predictor.fetch_and_predict(confidence_threshold)\n",
    "                    prediction_time = time.time() - prediction_start\n",
    "                    \n",
    "                    # Store performance data\n",
    "                    self.performance_metrics['prediction_times'].append(prediction_time)\n",
    "                    \n",
    "                    # Process and store result\n",
    "                    self._process_enhanced_result(result, confidence_threshold)\n",
    "                    \n",
    "                    # Update live statistics\n",
    "                    current_time = time.time()\n",
    "                    if show_live_stats and (current_time - last_stats_update) >= update_interval:\n",
    "                        self._update_live_stats()\n",
    "                        self._display_live_dashboard()\n",
    "                        last_stats_update = current_time\n",
    "                    \n",
    "                    # Maintain polling rate\n",
    "                    elapsed = time.time() - loop_start\n",
    "                    sleep_time = max(0, self.polling_interval - elapsed)\n",
    "                    if sleep_time > 0:\n",
    "                        time.sleep(sleep_time)\n",
    "                \n",
    "                print(\"\\\\nâœ… Enhanced continuous prediction completed!\")\n",
    "                self._display_final_summary()\n",
    "                \n",
    "            except KeyboardInterrupt:\n",
    "                print(\"\\\\nğŸ›‘ Enhanced prediction stopped by user\")\n",
    "                self._display_final_summary()\n",
    "            except Exception as e:\n",
    "                print(f\"\\\\nâŒ Error in enhanced prediction: {e}\")\n",
    "            finally:\n",
    "                self.is_running = False\n",
    "        \n",
    "        # Start in separate thread\n",
    "        self.thread = threading.Thread(target=enhanced_prediction_loop, daemon=True)\n",
    "        self.thread.start()\n",
    "        \n",
    "        return self.thread\n",
    "    \n",
    "    def _process_enhanced_result(self, result, confidence_threshold):\n",
    "        \"\"\"Process prediction result with enhanced data tracking\"\"\"\n",
    "        timestamp = time.time()\n",
    "        self.timestamp_history.append(timestamp)\n",
    "        self.live_stats['total_predictions'] += 1\n",
    "        self.live_stats['last_update_time'] = timestamp\n",
    "        \n",
    "        if result['success']:\n",
    "            character = result['character']\n",
    "            confidence = result['confidence']\n",
    "            \n",
    "            # Store prediction data\n",
    "            self.prediction_history.append(character)\n",
    "            self.confidence_history.append(confidence)\n",
    "            \n",
    "            # Store sensor data if available\n",
    "            if 'sensor_data' in result:\n",
    "                self.sensor_data_history.append(result['sensor_data'])\n",
    "            \n",
    "            # Update character frequency\n",
    "            if character not in self.live_stats['characters_this_session']:\n",
    "                self.live_stats['characters_this_session'][character] = 0\n",
    "            self.live_stats['characters_this_session'][character] += 1\n",
    "            \n",
    "            # Update current state\n",
    "            self.live_stats['current_character'] = character\n",
    "            self.live_stats['current_confidence'] = confidence\n",
    "            self.live_stats['successful_predictions'] += 1\n",
    "            \n",
    "            if confidence >= confidence_threshold:\n",
    "                self.live_stats['confident_predictions'] += 1\n",
    "    \n",
    "    def _update_live_stats(self):\n",
    "        \"\"\"Update live statistics\"\"\"\n",
    "        if self.live_stats['total_predictions'] > 0:\n",
    "            # Calculate average confidence\n",
    "            if self.confidence_history:\n",
    "                self.live_stats['average_confidence'] = np.mean(list(self.confidence_history))\n",
    "            \n",
    "            # Calculate prediction rate\n",
    "            elapsed = time.time() - self.live_stats['start_time']\n",
    "            if elapsed > 0:\n",
    "                self.live_stats['prediction_rate'] = self.live_stats['total_predictions'] / elapsed\n",
    "            \n",
    "            # Calculate data quality score (based on success rate and confidence)\n",
    "            success_rate = self.live_stats['successful_predictions'] / self.live_stats['total_predictions']\n",
    "            confidence_rate = self.live_stats['confident_predictions'] / self.live_stats['total_predictions']\n",
    "            self.live_stats['data_quality_score'] = (success_rate + confidence_rate) / 2\n",
    "    \n",
    "    def _display_live_dashboard(self):\n",
    "        \"\"\"Display real-time dashboard\"\"\"\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        print(\"ğŸ“Š LIVE BENGALI SIGN RECOGNITION DASHBOARD\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Current prediction\n",
    "        current_char = self.live_stats['current_character'] or 'None'\n",
    "        current_conf = self.live_stats['current_confidence']\n",
    "        print(f\"ğŸ¯ CURRENT: '{current_char}' ({current_conf:.1%} confidence)\")\n",
    "        \n",
    "        # Statistics\n",
    "        print(f\"\\\\nğŸ“ˆ LIVE STATISTICS:\")\n",
    "        print(f\"   â±ï¸ Running time: {time.time() - self.live_stats['start_time']:.1f}s\")\n",
    "        print(f\"   ğŸ“¡ Total predictions: {self.live_stats['total_predictions']}\")\n",
    "        print(f\"   âœ… Successful: {self.live_stats['successful_predictions']}\")\n",
    "        print(f\"   ğŸ’ª Confident: {self.live_stats['confident_predictions']}\")\n",
    "        print(f\"   ğŸ“Š Avg confidence: {self.live_stats['average_confidence']:.1%}\")\n",
    "        print(f\"   ğŸš€ Prediction rate: {self.live_stats['prediction_rate']:.1f} Hz\")\n",
    "        print(f\"   ğŸ¯ Data quality: {self.live_stats['data_quality_score']:.1%}\")\n",
    "        \n",
    "        # Character frequency\n",
    "        if self.live_stats['characters_this_session']:\n",
    "            print(f\"\\\\nğŸ”¤ CHARACTERS DETECTED:\")\n",
    "            sorted_chars = sorted(self.live_stats['characters_this_session'].items(), \n",
    "                                key=lambda x: x[1], reverse=True)\n",
    "            for char, count in sorted_chars[:5]:  # Show top 5\n",
    "                percentage = (count / self.live_stats['successful_predictions']) * 100\n",
    "                print(f\"   '{char}': {count} times ({percentage:.1f}%)\")\n",
    "        \n",
    "        # Performance metrics\n",
    "        if self.performance_metrics['prediction_times']:\n",
    "            avg_pred_time = np.mean(list(self.performance_metrics['prediction_times']))\n",
    "            print(f\"\\\\nâš¡ PERFORMANCE:\")\n",
    "            print(f\"   ğŸ”„ Avg prediction time: {avg_pred_time:.3f}s\")\n",
    "        \n",
    "        print(\"\\\\n\" + \"=\" * 60)\n",
    "    \n",
    "    def _display_final_summary(self):\n",
    "        \"\"\"Display comprehensive final summary\"\"\"\n",
    "        total_time = time.time() - self.live_stats['start_time']\n",
    "        \n",
    "        print(\"\\\\nğŸ“‹ ENHANCED PREDICTION SESSION SUMMARY\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # Basic statistics\n",
    "        print(f\"â° Total time: {total_time:.1f}s\")\n",
    "        print(f\"ğŸ“¡ Total predictions: {self.live_stats['total_predictions']}\")\n",
    "        print(f\"âœ… Successful predictions: {self.live_stats['successful_predictions']}\")\n",
    "        print(f\"ğŸ’ª Confident predictions: {self.live_stats['confident_predictions']}\")\n",
    "        \n",
    "        if self.live_stats['total_predictions'] > 0:\n",
    "            success_rate = (self.live_stats['successful_predictions'] / self.live_stats['total_predictions']) * 100\n",
    "            confidence_rate = (self.live_stats['confident_predictions'] / self.live_stats['total_predictions']) * 100\n",
    "            print(f\"ğŸ“Š Success rate: {success_rate:.1f}%\")\n",
    "            print(f\"ğŸ¯ Confidence rate: {confidence_rate:.1f}%\")\n",
    "        \n",
    "        # Character analysis\n",
    "        if self.live_stats['characters_this_session']:\n",
    "            print(f\"\\\\nğŸ”¤ CHARACTER DETECTION SUMMARY:\")\n",
    "            print(f\"   ğŸ“ Unique characters: {len(self.live_stats['characters_this_session'])}\")\n",
    "            \n",
    "            sorted_chars = sorted(self.live_stats['characters_this_session'].items(), \n",
    "                                key=lambda x: x[1], reverse=True)\n",
    "            print(\"   ğŸ† Most detected:\")\n",
    "            for i, (char, count) in enumerate(sorted_chars[:3]):\n",
    "                percentage = (count / self.live_stats['successful_predictions']) * 100\n",
    "                print(f\"      {i+1}. '{char}': {count} times ({percentage:.1f}%)\")\n",
    "        \n",
    "        # Performance summary\n",
    "        if self.performance_metrics['prediction_times']:\n",
    "            avg_time = np.mean(list(self.performance_metrics['prediction_times']))\n",
    "            min_time = np.min(list(self.performance_metrics['prediction_times']))\n",
    "            max_time = np.max(list(self.performance_metrics['prediction_times']))\n",
    "            print(f\"\\\\nâš¡ PERFORMANCE ANALYSIS:\")\n",
    "            print(f\"   ğŸ”„ Avg prediction time: {avg_time:.3f}s\")\n",
    "            print(f\"   âš¡ Fastest prediction: {min_time:.3f}s\")\n",
    "            print(f\"   ğŸŒ Slowest prediction: {max_time:.3f}s\")\n",
    "    \n",
    "    def stop_prediction(self):\n",
    "        \"\"\"Stop enhanced prediction\"\"\"\n",
    "        if self.is_running:\n",
    "            self.is_running = False\n",
    "            print(\"ğŸ›‘ Stopping enhanced prediction...\")\n",
    "            if self.thread:\n",
    "                self.thread.join(timeout=3)\n",
    "            print(\"âœ… Enhanced prediction stopped\")\n",
    "        else:\n",
    "            print(\"â„¹ï¸ Enhanced prediction not running\")\n",
    "    \n",
    "    def get_prediction_data(self):\n",
    "        \"\"\"Get all collected prediction data\"\"\"\n",
    "        return {\n",
    "            'predictions': list(self.prediction_history),\n",
    "            'confidences': list(self.confidence_history),\n",
    "            'sensor_data': list(self.sensor_data_history),\n",
    "            'timestamps': list(self.timestamp_history),\n",
    "            'live_stats': self.live_stats.copy(),\n",
    "            'performance_metrics': {k: list(v) for k, v in self.performance_metrics.items()}\n",
    "        }\n",
    "\n",
    "# Initialize Enhanced Continuous Predictor\n",
    "if bengali_predictor is not None:\n",
    "    print(\"ğŸš€ INITIALIZING ENHANCED CONTINUOUS PREDICTOR...\")\n",
    "    print(\"=\" * 55)\n",
    "    \n",
    "    enhanced_predictor = EnhancedContinuousPredictor(\n",
    "        bengali_predictor=bengali_predictor,\n",
    "        polling_interval=0.2  # 5 Hz\n",
    "    )\n",
    "    \n",
    "    print(\"ğŸ‰ Enhanced continuous predictor ready!\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ Cannot initialize enhanced predictor\")\n",
    "    enhanced_predictor = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fce20373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ INITIALIZING PREDICTION DATA ANALYZER...\n",
      "=============================================\n",
      "ğŸ“Š PredictionDataAnalyzer initialized\n",
      "ğŸ‰ Data analyzer ready!\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“Š Data Visualization and Analysis Tools\n",
    "class PredictionDataAnalyzer:\n",
    "    \"\"\"\n",
    "    Advanced data analysis and visualization for prediction results\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, enhanced_predictor):\n",
    "        \"\"\"Initialize analyzer with predictor data\"\"\"\n",
    "        self.enhanced_predictor = enhanced_predictor\n",
    "        print(\"ğŸ“Š PredictionDataAnalyzer initialized\")\n",
    "    \n",
    "    def plot_real_time_confidence(self, last_n_predictions=50):\n",
    "        \"\"\"Plot confidence levels over time\"\"\"\n",
    "        data = self.enhanced_predictor.get_prediction_data()\n",
    "        \n",
    "        if not data['confidences']:\n",
    "            print(\"âŒ No confidence data available\")\n",
    "            return\n",
    "        \n",
    "        confidences = data['confidences'][-last_n_predictions:]\n",
    "        timestamps = data['timestamps'][-last_n_predictions:]\n",
    "        \n",
    "        if timestamps:\n",
    "            # Convert to relative time (seconds from start)\n",
    "            start_time = timestamps[0]\n",
    "            relative_times = [(t - start_time) for t in timestamps]\n",
    "            \n",
    "            plt.figure(figsize=(12, 6))\n",
    "            plt.plot(relative_times, confidences, 'b-', linewidth=2, marker='o', markersize=4)\n",
    "            plt.axhline(y=0.8, color='g', linestyle='--', label='High Confidence (80%)')\n",
    "            plt.axhline(y=0.6, color='orange', linestyle='--', label='Medium Confidence (60%)')\n",
    "            plt.axhline(y=0.4, color='r', linestyle='--', label='Low Confidence (40%)')\n",
    "            \n",
    "            plt.xlabel('Time (seconds)')\n",
    "            plt.ylabel('Confidence Level')\n",
    "            plt.title(f'Real-Time Prediction Confidence (Last {len(confidences)} predictions)')\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            plt.legend()\n",
    "            plt.ylim(0, 1)\n",
    "            \n",
    "            # Add statistics\n",
    "            avg_conf = np.mean(confidences)\n",
    "            plt.text(0.02, 0.98, f'Avg: {avg_conf:.1%}', transform=plt.gca().transAxes, \n",
    "                    bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        \n",
    "        return confidences, relative_times\n",
    "    \n",
    "    def plot_character_frequency(self):\n",
    "        \"\"\"Plot character detection frequency\"\"\"\n",
    "        stats = self.enhanced_predictor.live_stats\n",
    "        char_data = stats.get('characters_this_session', {})\n",
    "        \n",
    "        if not char_data:\n",
    "            print(\"âŒ No character data available\")\n",
    "            return\n",
    "        \n",
    "        characters = list(char_data.keys())\n",
    "        frequencies = list(char_data.values())\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        bars = plt.bar(characters, frequencies, color='skyblue', edgecolor='darkblue')\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar, freq in zip(bars, frequencies):\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,\n",
    "                    str(freq), ha='center', va='bottom', fontweight='bold')\n",
    "        \n",
    "        plt.xlabel('Bengali Characters')\n",
    "        plt.ylabel('Detection Frequency')\n",
    "        plt.title('Character Detection Frequency During Session')\n",
    "        plt.grid(True, axis='y', alpha=0.3)\n",
    "        \n",
    "        # Add percentage annotations\n",
    "        total = sum(frequencies)\n",
    "        for i, (char, freq) in enumerate(char_data.items()):\n",
    "            percentage = (freq / total) * 100\n",
    "            plt.text(i, freq/2, f'{percentage:.1f}%', ha='center', va='center', \n",
    "                    color='white', fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return char_data\n",
    "    \n",
    "    def plot_prediction_timeline(self, last_n_predictions=100):\n",
    "        \"\"\"Plot prediction timeline with characters and confidence\"\"\"\n",
    "        data = self.enhanced_predictor.get_prediction_data()\n",
    "        \n",
    "        if not data['predictions']:\n",
    "            print(\"âŒ No prediction data available\")\n",
    "            return\n",
    "        \n",
    "        predictions = data['predictions'][-last_n_predictions:]\n",
    "        confidences = data['confidences'][-last_n_predictions:]\n",
    "        timestamps = data['timestamps'][-last_n_predictions:]\n",
    "        \n",
    "        if not timestamps:\n",
    "            return\n",
    "        \n",
    "        # Convert to relative time\n",
    "        start_time = timestamps[0]\n",
    "        relative_times = [(t - start_time) for t in timestamps]\n",
    "        \n",
    "        # Create figure with subplots\n",
    "        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 8), sharex=True)\n",
    "        \n",
    "        # Plot 1: Confidence over time\n",
    "        ax1.plot(relative_times, confidences, 'b-', linewidth=2, marker='o', markersize=3)\n",
    "        ax1.axhline(y=0.8, color='g', linestyle='--', alpha=0.7, label='High Confidence')\n",
    "        ax1.set_ylabel('Confidence Level')\n",
    "        ax1.set_title('Prediction Timeline: Confidence and Characters')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        ax1.legend()\n",
    "        ax1.set_ylim(0, 1)\n",
    "        \n",
    "        # Plot 2: Characters detected\n",
    "        unique_chars = list(set(predictions))\n",
    "        char_to_num = {char: i for i, char in enumerate(unique_chars)}\n",
    "        char_numbers = [char_to_num[char] for char in predictions]\n",
    "        \n",
    "        scatter = ax2.scatter(relative_times, char_numbers, c=confidences, \n",
    "                            cmap='viridis', s=50, alpha=0.8)\n",
    "        ax2.set_ylabel('Characters')\n",
    "        ax2.set_xlabel('Time (seconds)')\n",
    "        ax2.set_yticks(range(len(unique_chars)))\n",
    "        ax2.set_yticklabels(unique_chars)\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add colorbar\n",
    "        cbar = plt.colorbar(scatter, ax=ax2)\n",
    "        cbar.set_label('Confidence Level')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return predictions, confidences, relative_times\n",
    "    \n",
    "    def generate_session_report(self):\n",
    "        \"\"\"Generate comprehensive session report\"\"\"\n",
    "        data = self.enhanced_predictor.get_prediction_data()\n",
    "        stats = self.enhanced_predictor.live_stats\n",
    "        \n",
    "        if not data['predictions']:\n",
    "            print(\"âŒ No data available for report\")\n",
    "            return\n",
    "        \n",
    "        print(\"ğŸ“‹ COMPREHENSIVE SESSION REPORT\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # Session overview\n",
    "        total_time = stats.get('last_update_time', time.time()) - stats.get('start_time', time.time())\n",
    "        print(f\"â° Session Duration: {total_time:.1f} seconds\")\n",
    "        print(f\"ğŸ“Š Total Predictions: {len(data['predictions'])}\")\n",
    "        print(f\"ğŸš€ Average Rate: {len(data['predictions'])/total_time:.1f} predictions/sec\")\n",
    "        \n",
    "        # Confidence analysis\n",
    "        confidences = data['confidences']\n",
    "        if confidences:\n",
    "            print(f\"\\\\nğŸ’ª CONFIDENCE ANALYSIS:\")\n",
    "            print(f\"   ğŸ“ˆ Average: {np.mean(confidences):.1%}\")\n",
    "            print(f\"   ğŸ“Š Median: {np.median(confidences):.1%}\")\n",
    "            print(f\"   ğŸ” Maximum: {np.max(confidences):.1%}\")\n",
    "            print(f\"   ğŸ“‰ Minimum: {np.min(confidences):.1%}\")\n",
    "            print(f\"   ğŸ“ Std Dev: {np.std(confidences):.1%}\")\n",
    "            \n",
    "            # Confidence distribution\n",
    "            high_conf = sum(1 for c in confidences if c >= 0.8)\n",
    "            med_conf = sum(1 for c in confidences if 0.6 <= c < 0.8)\n",
    "            low_conf = sum(1 for c in confidences if c < 0.6)\n",
    "            \n",
    "            print(f\"\\\\nğŸ¯ CONFIDENCE DISTRIBUTION:\")\n",
    "            print(f\"   ğŸŸ¢ High (â‰¥80%): {high_conf} ({high_conf/len(confidences)*100:.1f}%)\")\n",
    "            print(f\"   ğŸŸ¡ Medium (60-80%): {med_conf} ({med_conf/len(confidences)*100:.1f}%)\")\n",
    "            print(f\"   ğŸ”´ Low (<60%): {low_conf} ({low_conf/len(confidences)*100:.1f}%)\")\n",
    "        \n",
    "        # Character analysis\n",
    "        char_data = stats.get('characters_this_session', {})\n",
    "        if char_data:\n",
    "            print(f\"\\\\nğŸ”¤ CHARACTER ANALYSIS:\")\n",
    "            print(f\"   ğŸ“ Unique Characters: {len(char_data)}\")\n",
    "            print(f\"   ğŸ† Most Frequent: '{max(char_data.items(), key=lambda x: x[1])[0]}'\")\n",
    "            print(f\"   ğŸ“Š Character Distribution:\")\n",
    "            \n",
    "            sorted_chars = sorted(char_data.items(), key=lambda x: x[1], reverse=True)\n",
    "            for char, count in sorted_chars:\n",
    "                percentage = (count / sum(char_data.values())) * 100\n",
    "                print(f\"      '{char}': {count} times ({percentage:.1f}%)\")\n",
    "        \n",
    "        # Performance metrics\n",
    "        perf_data = data['performance_metrics']\n",
    "        if perf_data.get('prediction_times'):\n",
    "            pred_times = perf_data['prediction_times']\n",
    "            print(f\"\\\\nâš¡ PERFORMANCE METRICS:\")\n",
    "            print(f\"   ğŸ”„ Avg Prediction Time: {np.mean(pred_times):.3f}s\")\n",
    "            print(f\"   âš¡ Fastest: {np.min(pred_times):.3f}s\")\n",
    "            print(f\"   ğŸŒ Slowest: {np.max(pred_times):.3f}s\")\n",
    "        \n",
    "        return data, stats\n",
    "\n",
    "# Initialize Data Analyzer\n",
    "if enhanced_predictor is not None:\n",
    "    print(\"ğŸš€ INITIALIZING PREDICTION DATA ANALYZER...\")\n",
    "    print(\"=\" * 45)\n",
    "    \n",
    "    data_analyzer = PredictionDataAnalyzer(enhanced_predictor)\n",
    "    \n",
    "    print(\"ğŸ‰ Data analyzer ready!\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ Cannot initialize analyzer - enhanced predictor not available\")\n",
    "    data_analyzer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "966e0c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‰ CONTINUOUS DATA PREDICTION SYSTEM READY!\n",
      "==================================================\n",
      "ğŸ’¡ Available Functions:\n",
      "\n",
      "ğŸš€ Main Functions:\n",
      "   â€¢ run_complete_continuous_demo(30) - Full 30s demo with analysis\n",
      "   â€¢ quick_continuous_test(10) - Quick 10s test\n",
      "   â€¢ quick_prediction_test() - Single prediction test\n",
      "\n",
      "ğŸ“Š Analysis Functions:\n",
      "   â€¢ data_analyzer.plot_real_time_confidence() - Confidence graph\n",
      "   â€¢ data_analyzer.plot_character_frequency() - Character distribution\n",
      "   â€¢ data_analyzer.generate_session_report() - Detailed report\n",
      "\n",
      "ğŸ”§ System Functions:\n",
      "   â€¢ check_system_status() - Check all components\n",
      "   â€¢ esp32_client.print_stats() - Connection statistics\n",
      "   â€¢ bengali_predictor.print_stats() - Prediction statistics\n",
      "\n",
      "ğŸš€ QUICK START: run_complete_continuous_demo(30)\n"
     ]
    }
   ],
   "source": [
    "# ğŸš€ Complete Continuous Prediction Demo System\n",
    "def run_complete_continuous_demo(duration=30, confidence_threshold=0.75, \n",
    "                                show_live_dashboard=True, generate_plots=True):\n",
    "    \"\"\"\n",
    "    Run a complete continuous prediction demo with all features\n",
    "    \n",
    "    Args:\n",
    "        duration: Demo duration in seconds\n",
    "        confidence_threshold: Minimum confidence for valid predictions\n",
    "        show_live_dashboard: Show real-time dashboard updates\n",
    "        generate_plots: Generate analysis plots after completion\n",
    "    \"\"\"\n",
    "    \n",
    "    if enhanced_predictor is None:\n",
    "        print(\"âŒ Enhanced predictor not available\")\n",
    "        return\n",
    "    \n",
    "    print(\"ğŸš€ COMPLETE CONTINUOUS BENGALI PREDICTION DEMO\")\n",
    "    print(\"=\" * 55)\n",
    "    print(f\"â° Duration: {duration} seconds\")\n",
    "    print(f\"ğŸ¯ Confidence threshold: {confidence_threshold:.1%}\")\n",
    "    print(f\"ğŸ“Š Live dashboard: {'Enabled' if show_live_dashboard else 'Disabled'}\")\n",
    "    print(f\"ğŸ“ˆ Post-analysis: {'Enabled' if generate_plots else 'Disabled'}\")\n",
    "    print()\n",
    "    print(\"ğŸ“± Instructions:\")\n",
    "    print(\"   â€¢ Make sure ESP32 glove is connected to Access Point\")\n",
    "    print(\"   â€¢ Perform Bengali sign gestures with your glove\")\n",
    "    print(\"   â€¢ Watch real-time predictions and statistics\")\n",
    "    print(\"   â€¢ Press Ctrl+C to stop early\")\n",
    "    print()\n",
    "    \n",
    "    # Check ESP32 connection\n",
    "    print(\"ğŸ” Testing ESP32 connection...\")\n",
    "    if esp32_client.test_connection():\n",
    "        print(\"âœ… ESP32 connection successful!\")\n",
    "    else:\n",
    "        print(\"âš ï¸ ESP32 connection failed - demo will continue but may show errors\")\n",
    "        print(\"ğŸ’¡ Make sure ESP32 is in Access Point mode at 192.168.4.1\")\n",
    "    \n",
    "    print(f\"\\\\nğŸ¬ Starting {duration}s continuous prediction demo...\")\n",
    "    print(\"ğŸ›‘ Press Ctrl+C to stop early\")\n",
    "    print(\"=\" * 55)\n",
    "    \n",
    "    # Start enhanced prediction\n",
    "    try:\n",
    "        thread = enhanced_predictor.start_enhanced_prediction(\n",
    "            duration_seconds=duration,\n",
    "            confidence_threshold=confidence_threshold,\n",
    "            show_live_stats=show_live_dashboard,\n",
    "            update_interval=3.0  # Update dashboard every 3 seconds\n",
    "        )\n",
    "        \n",
    "        # Wait for completion\n",
    "        if thread:\n",
    "            thread.join()\n",
    "            \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\\\nğŸ›‘ Demo stopped by user\")\n",
    "        enhanced_predictor.stop_prediction()\n",
    "    \n",
    "    # Generate analysis and plots\n",
    "    if generate_plots and data_analyzer is not None:\n",
    "        print(\"\\\\nğŸ“Š GENERATING POST-DEMO ANALYSIS...\")\n",
    "        print(\"=\" * 40)\n",
    "        \n",
    "        try:\n",
    "            # Generate comprehensive report\n",
    "            data_analyzer.generate_session_report()\n",
    "            \n",
    "            # Create visualizations\n",
    "            print(\"\\\\nğŸ“ˆ Creating visualizations...\")\n",
    "            \n",
    "            # 1. Confidence timeline\n",
    "            print(\"ğŸ“Š Plotting confidence timeline...\")\n",
    "            data_analyzer.plot_real_time_confidence(last_n_predictions=100)\n",
    "            \n",
    "            # 2. Character frequency\n",
    "            print(\"ğŸ“Š Plotting character frequency...\")\n",
    "            data_analyzer.plot_character_frequency()\n",
    "            \n",
    "            # 3. Prediction timeline\n",
    "            print(\"ğŸ“Š Plotting prediction timeline...\")\n",
    "            data_analyzer.plot_prediction_timeline(last_n_predictions=50)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Error generating plots: {e}\")\n",
    "    \n",
    "    # Show final system statistics\n",
    "    print(\"\\\\nğŸ“‹ FINAL SYSTEM STATUS:\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    if esp32_client:\n",
    "        esp32_client.print_stats()\n",
    "    \n",
    "    if bengali_predictor:\n",
    "        bengali_predictor.print_stats()\n",
    "    \n",
    "    print(\"\\\\nğŸ‰ Demo completed successfully!\")\n",
    "    \n",
    "    return enhanced_predictor.get_prediction_data()\n",
    "\n",
    "# ğŸ”§ Quick Test Functions\n",
    "def quick_prediction_test():\n",
    "    \"\"\"Quick single prediction test\"\"\"\n",
    "    print(\"ğŸ” QUICK PREDICTION TEST\")\n",
    "    print(\"=\" * 25)\n",
    "    \n",
    "    if bengali_predictor is None:\n",
    "        print(\"âŒ Predictor not available\")\n",
    "        return\n",
    "    \n",
    "    result = test_single_prediction(show_details=True)\n",
    "    return result\n",
    "\n",
    "def quick_continuous_test(duration=10):\n",
    "    \"\"\"Quick continuous prediction test\"\"\"\n",
    "    print(f\"âš¡ QUICK {duration}S CONTINUOUS TEST\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    if enhanced_predictor is None:\n",
    "        print(\"âŒ Enhanced predictor not available\")\n",
    "        return\n",
    "    \n",
    "    thread = enhanced_predictor.start_enhanced_prediction(\n",
    "        duration_seconds=duration,\n",
    "        confidence_threshold=0.7,\n",
    "        show_live_stats=True,\n",
    "        update_interval=2.0\n",
    "    )\n",
    "    \n",
    "    if thread:\n",
    "        try:\n",
    "            thread.join()\n",
    "        except KeyboardInterrupt:\n",
    "            enhanced_predictor.stop_prediction()\n",
    "    \n",
    "    return enhanced_predictor.get_prediction_data()\n",
    "\n",
    "# ğŸ“Š System Status Check\n",
    "def check_system_status():\n",
    "    \"\"\"Check status of all system components\"\"\"\n",
    "    print(\"ğŸ” SYSTEM STATUS CHECK\")\n",
    "    print(\"=\" * 25)\n",
    "    \n",
    "    # Check model\n",
    "    model_status = \"âœ… Ready\" if lstm_model is not None else \"âŒ Not loaded\"\n",
    "    print(f\"ğŸ¤– LSTM Model: {model_status}\")\n",
    "    \n",
    "    # Check preprocessing\n",
    "    preprocessing_status = \"âœ… Ready\" if (scaler is not None and label_encoder is not None) else \"âŒ Not loaded\"\n",
    "    print(f\"âš™ï¸ Preprocessing: {preprocessing_status}\")\n",
    "    \n",
    "    # Check ESP32 client\n",
    "    esp32_status = \"âœ… Initialized\" if esp32_client is not None else \"âŒ Not initialized\"\n",
    "    print(f\"ğŸ“¡ ESP32 Client: {esp32_status}\")\n",
    "    \n",
    "    # Check predictor\n",
    "    predictor_status = \"âœ… Ready\" if bengali_predictor is not None else \"âŒ Not initialized\"\n",
    "    print(f\"ğŸ§  Bengali Predictor: {predictor_status}\")\n",
    "    \n",
    "    # Check enhanced predictor\n",
    "    enhanced_status = \"âœ… Ready\" if enhanced_predictor is not None else \"âŒ Not initialized\"\n",
    "    print(f\"ğŸ“ˆ Enhanced Predictor: {enhanced_status}\")\n",
    "    \n",
    "    # Check analyzer\n",
    "    analyzer_status = \"âœ… Ready\" if data_analyzer is not None else \"âŒ Not initialized\"\n",
    "    print(f\"ğŸ“Š Data Analyzer: {analyzer_status}\")\n",
    "    \n",
    "    # Test ESP32 connection\n",
    "    print(\"\\\\nğŸ” Testing ESP32 connection...\")\n",
    "    if esp32_client and esp32_client.test_connection():\n",
    "        print(\"âœ… ESP32 Access Point: Connected\")\n",
    "    else:\n",
    "        print(\"âŒ ESP32 Access Point: Not connected\")\n",
    "    \n",
    "    print(\"\\\\nğŸ¯ SYSTEM READY FOR CONTINUOUS PREDICTION!\")\n",
    "\n",
    "print(\"ğŸ‰ CONTINUOUS DATA PREDICTION SYSTEM READY!\")\n",
    "print(\"=\" * 50)\n",
    "print(\"ğŸ’¡ Available Functions:\")\n",
    "print()\n",
    "print(\"ğŸš€ Main Functions:\")\n",
    "print(\"   â€¢ run_complete_continuous_demo(30) - Full 30s demo with analysis\")\n",
    "print(\"   â€¢ quick_continuous_test(10) - Quick 10s test\")\n",
    "print(\"   â€¢ quick_prediction_test() - Single prediction test\")\n",
    "print()\n",
    "print(\"ğŸ“Š Analysis Functions:\")\n",
    "print(\"   â€¢ data_analyzer.plot_real_time_confidence() - Confidence graph\")\n",
    "print(\"   â€¢ data_analyzer.plot_character_frequency() - Character distribution\") \n",
    "print(\"   â€¢ data_analyzer.generate_session_report() - Detailed report\")\n",
    "print()\n",
    "print(\"ğŸ”§ System Functions:\")\n",
    "print(\"   â€¢ check_system_status() - Check all components\")\n",
    "print(\"   â€¢ esp32_client.print_stats() - Connection statistics\")\n",
    "print(\"   â€¢ bengali_predictor.print_stats() - Prediction statistics\")\n",
    "print()\n",
    "print(\"ğŸš€ QUICK START: run_complete_continuous_demo(30)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5fbce107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” SYSTEM STATUS CHECK\n",
      "=========================\n",
      "ğŸ¤– LSTM Model: âœ… Ready\n",
      "âš™ï¸ Preprocessing: âœ… Ready\n",
      "ğŸ“¡ ESP32 Client: âœ… Initialized\n",
      "ğŸ§  Bengali Predictor: âœ… Ready\n",
      "ğŸ“ˆ Enhanced Predictor: âœ… Ready\n",
      "ğŸ“Š Data Analyzer: âœ… Ready\n",
      "\\nğŸ” Testing ESP32 connection...\n",
      "ğŸ” Testing connection to ESP32 at http://192.168.4.1:80...\n",
      "âš ï¸ ESP32 responded with status: 404\n",
      "âŒ ESP32 Access Point: Not connected\n",
      "\\nğŸ¯ SYSTEM READY FOR CONTINUOUS PREDICTION!\n"
     ]
    }
   ],
   "source": [
    "# ğŸ” Check System Status\n",
    "check_system_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b7ac3e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” DIAGNOSING PREDICTION ISSUES...\n",
      "=============================================\n",
      "ğŸ“¡ Step 1: Testing ESP32 connection at 192.168.4.1...\n",
      "ğŸ” Testing connection to ESP32 at http://192.168.4.1:80...\n",
      "âŒ Connection error: Cannot reach ESP32\n",
      "âŒ Connection failed, but let's try fetching data directly...\n",
      "\n",
      "ğŸ“Š Step 2: Testing sensor data fetching...\n",
      "âŒ No data from root endpoint, trying /data...\n",
      "âŒ No data from /data endpoint, trying direct request...\n",
      "âŒ Direct request failed: HTTPConnectionPool(host='192.168.4.1', port=80): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x722cf7a57ad0>, 'Connection to 192.168.4.1 timed out. (connect timeout=5)'))\n"
     ]
    }
   ],
   "source": [
    "# ğŸ” Diagnose Prediction Issues - Let's test step by step\n",
    "def diagnose_prediction_issue():\n",
    "    \"\"\"Comprehensive diagnosis of why predictions aren't working\"\"\"\n",
    "    \n",
    "    print(\"ğŸ” DIAGNOSING PREDICTION ISSUES...\")\n",
    "    print(\"=\" * 45)\n",
    "    \n",
    "    # Step 1: Test ESP32 connection with current IP\n",
    "    print(\"ğŸ“¡ Step 1: Testing ESP32 connection at 192.168.4.1...\")\n",
    "    esp32_client.esp32_ip = \"192.168.4.1\"\n",
    "    esp32_client.base_url = f\"http://192.168.4.1:{esp32_client.port}\"\n",
    "    \n",
    "    connection_test = esp32_client.test_connection()\n",
    "    if connection_test:\n",
    "        print(\"âœ… ESP32 connection successful!\")\n",
    "    else:\n",
    "        print(\"âŒ Connection failed, but let's try fetching data directly...\")\n",
    "    \n",
    "    # Step 2: Test data fetching\n",
    "    print(\"\\nğŸ“Š Step 2: Testing sensor data fetching...\")\n",
    "    sensor_data = esp32_client.get_sensor_data(\"/\")  # Try root endpoint\n",
    "    \n",
    "    if sensor_data is None:\n",
    "        print(\"âŒ No data from root endpoint, trying /data...\")\n",
    "        sensor_data = esp32_client.get_sensor_data(\"/data\")\n",
    "    \n",
    "    if sensor_data is None:\n",
    "        print(\"âŒ No data from /data endpoint, trying direct request...\")\n",
    "        try:\n",
    "            import requests\n",
    "            response = requests.get(\"http://192.168.4.1\", timeout=5)\n",
    "            print(f\"ğŸ“¡ Direct response status: {response.status_code}\")\n",
    "            print(f\"ğŸ“„ Response content: {response.text[:200]}...\")\n",
    "            \n",
    "            # Try to parse the CSV data manually\n",
    "            csv_text = response.text.strip()\n",
    "            if csv_text:\n",
    "                print(\"ğŸ”§ Attempting manual CSV parsing...\")\n",
    "                lines = [line.strip() for line in csv_text.split('\\n') if line.strip()]\n",
    "                if lines:\n",
    "                    data_line = lines[-1]\n",
    "                    print(f\"ğŸ“Š Latest data line: {data_line}\")\n",
    "                    \n",
    "                    try:\n",
    "                        values = [float(x.strip()) for x in data_line.split(',')]\n",
    "                        print(f\"âœ… Parsed {len(values)} sensor values: {values}\")\n",
    "                        \n",
    "                        # Create sensor data manually\n",
    "                        sensor_data = {\n",
    "                            'timestamp': time.time(),\n",
    "                            'sensor_data': values,\n",
    "                            'sensor_count': len(values)\n",
    "                        }\n",
    "                        print(\"âœ… Manual sensor data created successfully!\")\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f\"âŒ Error parsing CSV: {e}\")\n",
    "                        return\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Direct request failed: {e}\")\n",
    "            return\n",
    "    \n",
    "    if sensor_data:\n",
    "        print(f\"âœ… Sensor data received: {sensor_data}\")\n",
    "    else:\n",
    "        print(\"âŒ No sensor data available - cannot proceed with prediction\")\n",
    "        return\n",
    "    \n",
    "    # Step 3: Test model input requirements\n",
    "    print(f\"\\nğŸ§  Step 3: Checking model requirements...\")\n",
    "    print(f\"   ğŸ“Š Model input shape: {bengali_predictor.input_shape}\")\n",
    "    print(f\"   ğŸ“ Sequence length needed: {bengali_predictor.sequence_length}\")\n",
    "    print(f\"   ğŸ¯ Features per step needed: {bengali_predictor.feature_count}\")\n",
    "    print(f\"   ğŸ“¡ Sensor values available: {len(sensor_data['sensor_data'])}\")\n",
    "    \n",
    "    if len(sensor_data['sensor_data']) < bengali_predictor.feature_count:\n",
    "        print(f\"âš ï¸ WARNING: Need {bengali_predictor.feature_count} features, got {len(sensor_data['sensor_data'])}\")\n",
    "        print(\"ğŸ”§ Padding or truncating to match model requirements...\")\n",
    "        \n",
    "        # Fix the sensor data to match model requirements\n",
    "        sensor_values = sensor_data['sensor_data']\n",
    "        if len(sensor_values) < bengali_predictor.feature_count:\n",
    "            # Pad with zeros\n",
    "            sensor_values.extend([0.0] * (bengali_predictor.feature_count - len(sensor_values)))\n",
    "        else:\n",
    "            # Truncate\n",
    "            sensor_values = sensor_values[:bengali_predictor.feature_count]\n",
    "        \n",
    "        sensor_data['sensor_data'] = sensor_values\n",
    "        print(f\"âœ… Adjusted sensor data: {len(sensor_data['sensor_data'])} values\")\n",
    "    \n",
    "    # Step 4: Test manual prediction\n",
    "    print(f\"\\nğŸ¯ Step 4: Testing manual prediction...\")\n",
    "    \n",
    "    # Clear the buffer first\n",
    "    bengali_predictor.data_buffer.clear()\n",
    "    print(f\"ğŸ§¹ Cleared data buffer\")\n",
    "    \n",
    "    # Add sensor data to buffer\n",
    "    features = sensor_data['sensor_data'][:bengali_predictor.feature_count]\n",
    "    bengali_predictor.data_buffer.append(features)\n",
    "    print(f\"ğŸ“Š Added data to buffer: {len(bengali_predictor.data_buffer)}/{bengali_predictor.sequence_length}\")\n",
    "    \n",
    "    # Since sequence_length is 1, we should be able to predict immediately\n",
    "    if len(bengali_predictor.data_buffer) >= bengali_predictor.sequence_length:\n",
    "        try:\n",
    "            print(\"ğŸ”„ Attempting prediction...\")\n",
    "            \n",
    "            # Prepare data\n",
    "            sequence_data = np.array(list(bengali_predictor.data_buffer))\n",
    "            print(f\"ğŸ“Š Sequence data shape: {sequence_data.shape}\")\n",
    "            \n",
    "            sequence_data_scaled = bengali_predictor.scaler.transform(sequence_data)\n",
    "            print(f\"ğŸ“Š Scaled data shape: {sequence_data_scaled.shape}\")\n",
    "            \n",
    "            prediction_input = sequence_data_scaled.reshape(1, bengali_predictor.sequence_length, bengali_predictor.feature_count)\n",
    "            print(f\"ğŸ“Š Prediction input shape: {prediction_input.shape}\")\n",
    "            \n",
    "            # Make prediction\n",
    "            prediction_probs = bengali_predictor.lstm_model.predict(prediction_input, verbose=0)\n",
    "            predicted_class_idx = np.argmax(prediction_probs[0])\n",
    "            confidence = float(prediction_probs[0][predicted_class_idx])\n",
    "            \n",
    "            # Decode character\n",
    "            predicted_character = bengali_predictor.label_encoder.inverse_transform([predicted_class_idx])[0]\n",
    "            \n",
    "            print(f\"ğŸ‰ PREDICTION SUCCESSFUL!\")\n",
    "            print(f\"   ğŸ”¤ Character: '{predicted_character}'\")\n",
    "            print(f\"   ğŸ’ª Confidence: {confidence:.1%}\")\n",
    "            print(f\"   ğŸ“Š All probabilities: {prediction_probs[0]}\")\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Prediction failed: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return False\n",
    "    else:\n",
    "        print(f\"âŒ Buffer not ready: {len(bengali_predictor.data_buffer)}/{bengali_predictor.sequence_length}\")\n",
    "        return False\n",
    "\n",
    "# Run the diagnosis\n",
    "diagnose_prediction_issue()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JupyterProject (.venv)",
   "language": "python",
   "name": "jupyterproject"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
